# MCP トークン最適化 - 決定方針

*決定日: 2026年1月*

---

## 採用アプローチ

### 1. MCP ツール改善方式: Anthropic 提唱方式

**コード実行方式（Code Execution Approach）** を採用する。

| 項目 | 内容 |
|------|------|
| **方式名** | コード実行方式（Anthropic 提唱） |
| **期待効果** | トークン消費 最大98.7% 削減 |
| **原理** | LLMがツールを直接呼び出す代わりに、コードを書いて実行環境に処理を委譲 |

**採用理由:**

- MCPのコンテキスト圧迫の2大原因を両方解決できる唯一のアプローチ
  - 原因1: ツール定義の肥大化 → ファイルシステム探索で必要なツールのみロード
  - 原因2: 中間データの重複通過 → 実行環境内でデータ処理が完結
- Anthropic 公式のエンジニアリングブログで推奨されている手法

---

### 2. コード実行環境: 分離型アプローチ

**外部の Code Interpreter MCP サーバー** を導入する。

| 項目 | 内容 |
|------|------|
| **方式名** | 分離型（Separated Approach） |
| **構成** | Code Interpreter MCP + GROWI MCP Server |
| **特徴** | コード実行環境を外部に委譲し、GROWI MCP は API 提供に専念 |

**採用理由:**

- **関心の分離**: GROWI MCP は API 提供に専念、コード実行は専門のサーバーに委譲
- **既存実装の活用**: セキュリティ対策済みの Code Interpreter 実装を利用可能
- **保守コストの軽減**: サンドボックスの脆弱性対応を外部に依存
- **汎用性**: 同じ Code Interpreter で他の MCP サーバーも利用可能

---

## 期待される効果

```
従来方式（全ツール定義ロード）
├── 起動時: 全22ツール定義 → 約5,000トークン消費
├── ツール呼び出し: 結果データがすべてLLMを通過
└── 複数ツール連携: 中間データが都度LLMを通過

↓ コード実行方式（分離型）適用後

├── 起動時: executeCode のみ → 数百トークン
├── ツール呼び出し: 必要なツール定義のみオンデマンドで読み込み
└── 複数ツール連携: 実行環境内で完結、console.log の出力のみLLMに返却
```

**定量的効果:**

- ツール定義によるトークン消費: **90%以上削減**
- 中間データによるトークン消費: **98%以上削減**（Anthropic 実績値）

---

## 関連ドキュメント

| ドキュメント | 内容 |
|--------------|------|
| [architecture.md](./architecture.md) | アーキテクチャ設計の詳細 |
| [implementation-plan.md](./implementation-plan.md) | 実装計画（ストーリーとタスク） |
| [research/](./research/) | 調査・検討時の資料（各種アプローチの比較など） |

---

## 参考資料

- [Code execution with MCP: building more efficient AI agents - Anthropic](https://www.anthropic.com/engineering/code-execution-with-mcp)
